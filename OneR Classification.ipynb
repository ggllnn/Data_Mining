{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235f37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "dataset = load_iris() \n",
    "X = dataset.data \n",
    "y = dataset.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d42f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b27e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492d6444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102ce6e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5445e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Compute the mean for each attribute计算列平均值\n",
    "attribute_means = X.mean(axis=0)\n",
    "X_d = np.array(X >= attribute_means, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726e1c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84333333, 3.05733333, 3.758     , 1.19933333])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec55c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb71d5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_d[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0239b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据有 (112,) 条\n",
      "测试集数据有 (38,) 条\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设置随机数种子以便复现书里的内容\n",
    "random_state = 14\n",
    "# sklearn.model_selection.train_test_split \\\n",
    "# (*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "# train_size defaut None = 25% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_d, y, random_state=random_state)\n",
    "print(\"训练集数据有 {} 条\".format(y_train.shape))\n",
    "print(\"测试集数据有 {} 条\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565cc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def train(X, y_true, feature):\n",
    "    \"\"\"Computes the predictors and error for a given feature using the OneR algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array [n_samples, n_features]\n",
    "        The two dimensional array that holds the dataset. Each row is a sample, each column\n",
    "        is a feature.\n",
    "    \n",
    "    y_true: array [n_samples,]\n",
    "        The one dimensional array that holds the class values. Corresponds to X, such that\n",
    "        y_true[i] is the class value for sample X[i].\n",
    "    \n",
    "    feature: int\n",
    "        An integer corresponding to the index of the variable we wish to test.\n",
    "        0 <= variable < n_features\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    predictors: dictionary of tuples: (value, prediction)\n",
    "        For each item in the array, if the variable has a given value, make the given prediction.\n",
    "    \n",
    "    error: float\n",
    "        The ratio of training data that this rule incorrectly predicts.\n",
    "    \"\"\"\n",
    "    # 1.一些等下要用的变量（数据的形状如上）\n",
    "    n_samples, n_features = X.shape\n",
    "    assert 0 <= feature < n_features\n",
    "    values = set(X[:,feature])\n",
    "    predictors = dict()\n",
    "    errors = []\n",
    "    \n",
    "    # 2.算法（对照上面的算法流程）\n",
    "    # 已经给定特征 feature，作为函数参数传过来了\n",
    "    for current_value in values: \n",
    "    # For 该特征对应的真值（即植物是哪一类）\n",
    "    \n",
    "        most_frequent_class, error = train_feature_value(X, y_true, feature, current_value) \n",
    "        # 预测值：基于该特征预测的次数最多的类，即在所有样本里该特征 10 次有 6 次预测了 A 类，那我们对所有样本都预测为 A 类\n",
    "        \n",
    "        predictors[current_value] = most_frequent_class\n",
    "        errors.append(error)\n",
    "        # 计算预测值与真值的误差\n",
    "    \n",
    "    total_error = sum(errors)\n",
    "    # 对上面计算的误差求和\n",
    "    # python里求和函数 sum([1, 2, 3]) == 1 + 2 + 3 == 6\n",
    "    \n",
    "    return predictors, total_error\n",
    "\n",
    "# Compute what our predictors say each sample is based on its value\n",
    "#y_predicted = np.array([predictors[sample[feature]] for sample in X])\n",
    "    \n",
    "#下面创建函数声明，参数分别是数据集、类别数组、选好的特征索引值、特征值\n",
    "def train_feature_value(X, y_true, feature, value):\n",
    "    # 预测值：基于该特征预测的次数最多的类，即在所有样本里该特征 10 次有 6 次预测了 A 类，那我们对所有样本都预测为 A 类\n",
    "    # 我们需要一个字典型变量存每个变量预测正确的次数\n",
    "    class_counts = defaultdict(int)\n",
    "    # 对每个二元组（类别，真值）迭代计数\n",
    "    for sample, y in zip(X, y_true):\n",
    "        if sample[feature] == value:\n",
    "            class_counts[y] += 1\n",
    "    # 现在选被预测最多的类别，需要排序。（我们认为被预测最多的类别就是正确的）\n",
    "    sorted_class_counts = sorted(class_counts.items(), key=itemgetter(1), reverse=True)\n",
    "    most_frequent_class = sorted_class_counts[0][0]\n",
    "    # 误差定义为分类“错误”的次数，这里“错误”指样本中没有分类为我们预测的值，即样本的真实类别不是“被预测最多的类别”\n",
    "    n_samples = X.shape[1]\n",
    "    error = sum([class_count for class_value, class_count in class_counts.items()\n",
    "                 if class_value != most_frequent_class])\n",
    "    return most_frequent_class, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b25526f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
       "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
       "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
       "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
       "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9024751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "701dfbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型基于第 2 个变量，误差为 37.00\n",
      "{'variable': 2, 'predictor': {0: 0, 1: 2}}\n"
     ]
    }
   ],
   "source": [
    "# For 给定的每个特征，计算所有预测值（这里 for 写到 list 里面是 python 的语法糖）\n",
    "all_predictors = {variable: train(X_train, y_train, variable) for variable in range(X_train.shape[1])}\n",
    "errors = {variable: error for variable, (mapping, error) in all_predictors.items()}\n",
    "# 现在选择最佳模型并保存为 \"model\"\n",
    "# 按误差排序\n",
    "best_variable, best_error = sorted(errors.items(), key=itemgetter(1))[0]\n",
    "print(\"最佳模型基于第 {0} 个变量，误差为 {1:.2f}\".format(best_variable, best_error))\n",
    "\n",
    "# 选最好的模型，也就是误差最小的模型\n",
    "model = {'variable': best_variable,\n",
    "         'predictor': all_predictors[best_variable][0]}\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de6b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model):\n",
    "    variable = model['variable']\n",
    "    predictor = model['predictor']\n",
    "    y_predicted = np.array([predictor[int(sample[variable])] for sample in X_test])\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be0b9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 2 2 0 2 0 2 2 0 2 2 0 2 0 2 2 2 0 0 0 2 0 2 0 2 2 0 0 0 2 0 2 0 2\n",
      " 2]\n",
      "在测试集上的准确率 65.8%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        17\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.40      1.00      0.57         8\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.45      0.67      0.51        38\n",
      "weighted avg       0.51      0.66      0.55        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_predicted = predict(X_test, model)\n",
    "print(y_predicted)\n",
    "accuracy = np.mean(y_predicted == y_test) * 100\n",
    "print(\"在测试集上的准确率 {:.1f}%\".format(accuracy))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c85147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfd2a64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 41, 1: 58, 2: 37, 3: 37}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45f8b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ({0: 0, 1: 2}, 41),\n",
       " 1: ({0: 1, 1: 0}, 58),\n",
       " 2: ({0: 0, 1: 2}, 37),\n",
       " 3: ({0: 0, 1: 2}, 37)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12164b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 2}, 41)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e31a4cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(X[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e8fcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_value(X_train, y_train, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f2a5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 22)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_value(X_train, y_train, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c23c69e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_value(X_train, y_train, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b23da19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "117c267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型基于第 3 个变量，误差为 5.00\n",
      "{'variable': 3, 'predictor': {0.2: 0, 1.5: 1, 1.2: 1, 1.8: 2, 0.4: 0, 1.9: 2, 1.4: 1, 1.3: 1, 2.0: 2, 2.3: 2, 2.4: 2, 1.0: 1, 2.5: 2, 0.6: 0, 1.6: 1, 1.1: 1, 2.1: 2, 1.7: 1, 0.1: 0, 2.2: 2, 0.3: 0}}\n"
     ]
    }
   ],
   "source": [
    "# For 给定的每个特征，计算所有预测值（这里 for 写到 list 里面是 python 的语法糖）\n",
    "all_predictors2 = {variable: train(X_train2, y_train2, variable) for variable in range(X_train2.shape[1])}\n",
    "errors2 = {variable: error for variable, (mapping, error) in all_predictors2.items()}\n",
    "# 现在选择最佳模型并保存为 \"model\"\n",
    "# 按误差排序\n",
    "best_variable2, best_error2 = sorted(errors2.items(), key=itemgetter(1))[0]\n",
    "print(\"最佳模型基于第 {0} 个变量，误差为 {1:.2f}\".format(best_variable2, best_error2))\n",
    "\n",
    "# 选最好的模型，也就是误差最小的模型\n",
    "model2 = {'variable': best_variable2,\n",
    "         'predictor': all_predictors2[best_variable2][0]}\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b67bd852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model2['predictor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "028a4d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(X[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fad6634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1,\n",
       " 0.2,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 1.0,\n",
       " 1.1,\n",
       " 1.2,\n",
       " 1.3,\n",
       " 1.4,\n",
       " 1.5,\n",
       " 1.6,\n",
       " 1.7,\n",
       " 1.8,\n",
       " 1.9,\n",
       " 2.0,\n",
       " 2.1,\n",
       " 2.2,\n",
       " 2.3,\n",
       " 2.4,\n",
       " 2.5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train2[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f1e0916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2, 0.3, 0.4, 0.5, 1.0, 1.1, 1.2, 1.3, 1.5, 1.7, 1.8, 2.0, 2.1, 2.3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_test2[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "483c7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2modify = np.column_stack((X_test2, y_test2))[np.column_stack((X_test2, y_test2))[:,3]!=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "954fe0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = test2modify[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e78243cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2, 0.3, 0.4, 1.0, 1.1, 1.2, 1.3, 1.5, 1.7, 1.8, 2.0, 2.1, 2.3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_test2[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f06eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = test2modify[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6dc4c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9162fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(X_test2, model2):\n",
    "    variable = model2['variable']\n",
    "    predictor = model2['predictor']\n",
    "    y_predicted = np.array([predictor[(sample[variable])] for sample in X_test2])\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7b55436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 2 1 0 1 1 1 0 2 2 0 1 0 2 2 1 0 0 0 1 0 2 0 1 1 0 0 1 1 0 1 0 2 1]\n",
      "在测试集上的准确率 97.30%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        16\n",
      "         1.0       0.93      1.00      0.96        13\n",
      "         2.0       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.97        37\n",
      "   macro avg       0.98      0.96      0.97        37\n",
      "weighted avg       0.97      0.97      0.97        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted2 = predict2(X_test2, model2)\n",
    "print(y_predicted2)\n",
    "accuracy2 = np.mean(y_predicted2 == y_test2) * 100\n",
    "print(\"在测试集上的准确率 {:.2f}%\".format(accuracy2))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test2, y_predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e862ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(errors2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93ad011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 41, 1: 58, 2: 37, 3: 37}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a6bbe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, ({0: 0, 1: 2}, 41)), (1, ({0: 1, 1: 0}, 58)), (2, ({0: 0, 1: 2}, 37)), (3, ({0: 0, 1: 2}, 37))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictors.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c7b2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.column_stack((X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e795071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x[i] for i in range(len(x[:,3])) if x[:,3][i] in X_train2[:,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "864e1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c88ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
